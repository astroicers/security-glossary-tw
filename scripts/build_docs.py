#!/usr/bin/env python3
"""
Build documentation and API from YAML term definitions.

This script generates:
1. Markdown files for each term in docs/glossary/
2. JSON API files in docs/api/v1/
3. Index pages for glossary and categories
"""

from __future__ import annotations

import json
from pathlib import Path

import yaml

# Paths
ROOT_DIR = Path(__file__).parent.parent
TERMS_DIR = ROOT_DIR / "terms"
META_DIR = ROOT_DIR / "meta"
DOCS_DIR = ROOT_DIR / "docs"
GLOSSARY_DIR = DOCS_DIR / "glossary"
CATEGORIES_DIR = DOCS_DIR / "categories"
API_DIR = DOCS_DIR / "api" / "v1"
API_TERMS_DIR = API_DIR / "terms"


def load_categories() -> dict[str, dict]:
    """Load category definitions."""
    categories_file = META_DIR / "categories.yaml"
    with open(categories_file, encoding="utf-8") as f:
        data = yaml.safe_load(f)
    return {cat["id"]: cat for cat in data.get("categories", [])}


def load_all_terms() -> list[dict]:
    """Load all terms from YAML files."""
    terms = []
    for yaml_file in sorted(TERMS_DIR.glob("*.yaml")):
        with open(yaml_file, encoding="utf-8") as f:
            data = yaml.safe_load(f)
        if data and "terms" in data:
            terms.extend(data["terms"])
    return terms


def generate_term_markdown(term: dict, categories: dict[str, dict]) -> str:
    """Generate markdown content for a single term."""
    term_id = term["id"]
    term_en = term["term_en"]
    term_zh = term["term_zh"]
    definitions = term.get("definitions", {})
    brief = definitions.get("brief", "")
    standard = definitions.get("standard", "")
    category_id = term.get("category", "")
    category = categories.get(category_id, {})
    category_name = category.get("name_zh", category_id)
    category_icon = category.get("icon", "ğŸ“š")

    lines = [
        f"# {term_en}",
        "",
        f"**{term_zh}**",
        "",
        f"!!! info \"{brief}\"",
        "",
    ]

    # Category badge
    lines.extend([
        f"<span class=\"md-tag\">{category_icon} {category_name}</span>",
        "",
    ])

    # Standard definition
    if standard:
        lines.extend([
            "## å®šç¾©",
            "",
            standard.strip(),
            "",
        ])

    # Aliases
    aliases = term.get("aliases", {})
    zh_aliases = aliases.get("zh", [])
    en_aliases = aliases.get("en", [])
    if zh_aliases or en_aliases:
        lines.extend([
            "## åˆ¥å",
            "",
        ])
        if zh_aliases:
            lines.append(f"- ä¸­æ–‡ï¼š{', '.join(zh_aliases)}")
        if en_aliases:
            lines.append(f"- è‹±æ–‡ï¼š{', '.join(en_aliases)}")
        lines.append("")

    # Related terms
    related = term.get("related_terms", [])
    if related:
        lines.extend([
            "## ç›¸é—œè¡“èª",
            "",
        ])
        for rel_id in related:
            lines.append(f"- [{rel_id}](../{rel_id}/)")
        lines.append("")

    # Tags
    tags = term.get("tags", [])
    if tags:
        lines.extend([
            "## æ¨™ç±¤",
            "",
            " ".join(f"`{tag}`" for tag in tags),
            "",
        ])

    # Usage examples
    usage = term.get("usage", {})
    examples = usage.get("examples", [])
    if examples:
        lines.extend([
            "## ä½¿ç”¨ç¯„ä¾‹",
            "",
        ])
        for example in examples:
            lines.append(f"> {example}")
            lines.append("")

    # Avoid terms
    avoid = usage.get("avoid", [])
    if avoid:
        lines.extend([
            "!!! warning \"é¿å…ä½¿ç”¨\"",
            f"    ä»¥ä¸‹ç”¨èªä¸å»ºè­°ä½¿ç”¨ï¼š{', '.join(avoid)}",
            "",
        ])

    # References
    references = term.get("references", {})
    if references:
        lines.extend([
            "## åƒè€ƒè³‡æ–™",
            "",
        ])
        for ref_name, ref_url in references.items():
            display_name = ref_name.replace("_", " ").title()
            lines.append(f"- [{display_name}]({ref_url})")
        lines.append("")

    return "\n".join(lines)


def generate_term_json(term: dict) -> dict:
    """Generate JSON representation for a single term."""
    return {
        "id": term["id"],
        "term_en": term["term_en"],
        "term_zh": term["term_zh"],
        "definitions": term.get("definitions", {}),
        "category": term.get("category", ""),
        "subcategory": term.get("subcategory", ""),
        "tags": term.get("tags", []),
        "related_terms": term.get("related_terms", []),
        "aliases": term.get("aliases", {}),
    }


def generate_glossary_index(terms: list[dict], categories: dict[str, dict]) -> str:
    """Generate glossary index page."""
    lines = [
        "# è¡“èªåº«",
        "",
        "è³‡å®‰è¡“èªå®Œæ•´åˆ—è¡¨ï¼Œé»æ“Šè¡“èªæŸ¥çœ‹è©³ç´°èªªæ˜ã€‚",
        "",
        f"å…±æ”¶éŒ„ **{len(terms)}** å€‹è¡“èªã€‚",
        "",
    ]

    # Group by category
    by_category: dict[str, list[dict]] = {}
    for term in terms:
        cat_id = term.get("category", "other")
        if cat_id not in by_category:
            by_category[cat_id] = []
        by_category[cat_id].append(term)

    # Generate sections
    for cat_id, cat_terms in sorted(by_category.items()):
        cat = categories.get(cat_id, {})
        cat_name = cat.get("name_zh", cat_id)
        cat_icon = cat.get("icon", "ğŸ“š")

        lines.extend([
            f"## {cat_icon} {cat_name}",
            "",
            "| è‹±æ–‡ | ä¸­æ–‡ | èªªæ˜ |",
            "|------|------|------|",
        ])

        for term in sorted(cat_terms, key=lambda t: t["term_en"].lower()):
            term_id = term["id"]
            term_en = term["term_en"]
            term_zh = term["term_zh"]
            brief = term.get("definitions", {}).get("brief", "")
            lines.append(f"| [{term_en}]({term_id}/) | {term_zh} | {brief} |")

        lines.append("")

    return "\n".join(lines)


def generate_categories_index(terms: list[dict], categories: dict[str, dict]) -> str:
    """Generate categories index page."""
    lines = [
        "# åˆ†é¡ç€è¦½",
        "",
        "ä¾åˆ†é¡ç€è¦½è³‡å®‰è¡“èªã€‚",
        "",
    ]

    # Count terms per category
    counts: dict[str, int] = {}
    for term in terms:
        cat_id = term.get("category", "other")
        counts[cat_id] = counts.get(cat_id, 0) + 1

    # Generate category cards
    for cat_id, cat in categories.items():
        cat_name = cat.get("name_zh", cat_id)
        cat_icon = cat.get("icon", "ğŸ“š")
        cat_desc = cat.get("description", "")
        count = counts.get(cat_id, 0)

        lines.extend([
            f"## {cat_icon} {cat_name}",
            "",
            f"{cat_desc}",
            "",
            f"å…± **{count}** å€‹è¡“èª â†’ [æŸ¥çœ‹å…¨éƒ¨](../glossary/)",
            "",
        ])

    return "\n".join(lines)


def generate_api_index() -> str:
    """Generate API documentation page."""
    return """# API æ–‡ä»¶

è³‡å®‰è¡“èªåº«æä¾›éœæ…‹ JSON APIï¼Œå¯ä¾›å…¶ä»–æ‡‰ç”¨ç¨‹å¼ä½¿ç”¨ã€‚

## ç«¯é»

### å–å¾—æ‰€æœ‰è¡“èª

```
GET /api/v1/terms.json
```

å›å‚³æ‰€æœ‰è¡“èªçš„åˆ—è¡¨ã€‚

### å–å¾—å–®ä¸€è¡“èª

```
GET /api/v1/terms/{term_id}.json
```

å›å‚³æŒ‡å®šè¡“èªçš„è©³ç´°è³‡è¨Šã€‚

**ç¯„ä¾‹ï¼š**

```
GET /api/v1/terms/apt.json
```

### å–å¾—æ‰€æœ‰åˆ†é¡

```
GET /api/v1/categories.json
```

å›å‚³æ‰€æœ‰åˆ†é¡çš„åˆ—è¡¨ã€‚

## å›æ‡‰æ ¼å¼

### è¡“èªç‰©ä»¶

```json
{
  "id": "apt",
  "term_en": "APT",
  "term_zh": "é€²éšæŒçºŒæ€§å¨è„…",
  "definitions": {
    "brief": "åœ‹å®¶ç´šé§­å®¢çµ„ç¹”ç™¼å‹•çš„é•·æœŸç¶²è·¯æ”»æ“Š",
    "standard": "é€²éšæŒçºŒæ€§å¨è„…æ˜¯ä¸€ç¨®..."
  },
  "category": "threat_actors",
  "tags": ["åœ‹å®¶ç´š", "é•·æœŸæ”»æ“Š"],
  "related_terms": ["apt_group", "nation_state"]
}
```

## ä½¿ç”¨ç¯„ä¾‹

### JavaScript

```javascript
fetch('https://astroicers.github.io/security-glossary-tw/api/v1/terms/apt.json')
  .then(response => response.json())
  .then(term => {
    console.log(term.term_zh); // é€²éšæŒçºŒæ€§å¨è„…
  });
```

### Python

```python
import requests

resp = requests.get(
    'https://astroicers.github.io/security-glossary-tw/api/v1/terms/apt.json'
)
term = resp.json()
print(term['term_zh'])  # é€²éšæŒçºŒæ€§å¨è„…
```

## CORS

éœæ…‹æª”æ¡ˆé€é GitHub Pages æä¾›ï¼Œæ”¯æ´è·¨åŸŸè«‹æ±‚ã€‚
"""


def generate_home_page(terms: list[dict], categories: dict[str, dict]) -> str:
    """Generate home page."""
    return f"""# è³‡å®‰è¡“èªåº«

æ­¡è¿ä½¿ç”¨ **Security Glossary TW** - ç¹é«”ä¸­æ–‡è³‡å®‰è¡“èªæ¨™æº–åŒ–è©å½™åº«ã€‚

## ğŸ“Š çµ±è¨ˆ

- è¡“èªç¸½æ•¸ï¼š**{len(terms)}**
- åˆ†é¡æ•¸é‡ï¼š**{len(categories)}**

## ğŸ” å¿«é€Ÿé–‹å§‹

- [ç€è¦½è¡“èªåº«](glossary/) - æŸ¥çœ‹æ‰€æœ‰è¡“èª
- [åˆ†é¡ç€è¦½](categories/) - ä¾åˆ†é¡æŸ¥æ‰¾
- [API æ–‡ä»¶](api.md) - ç¨‹å¼åŒ–å­˜å–

## ğŸ’¡ ç”¨é€”

æ­¤è¡“èªåº«å¯ç”¨æ–¼ï¼š

1. **çµ±ä¸€ç¿»è­¯** - ç¢ºä¿åœ˜éšŠä½¿ç”¨ä¸€è‡´çš„è³‡å®‰è¡“èªç¿»è­¯
2. **å ±å‘Šæ’°å¯«** - åœ¨è³‡å®‰å ±å‘Šä¸­ä½¿ç”¨æ¨™æº–åŒ–ç”¨èª
3. **æ•™è‚²è¨“ç·´** - å­¸ç¿’è³‡å®‰å°ˆæ¥­è©å½™
4. **è‡ªå‹•åŒ–å·¥å…·** - é€é API æ•´åˆåˆ°å…¶ä»–ç³»çµ±

## ğŸ”— é€£çµ

- [GitHub å°ˆæ¡ˆ](https://github.com/astroicers/security-glossary-tw)
- [PyPI å¥—ä»¶](https://pypi.org/project/security-glossary-tw/)

## ğŸ“ è²¢ç»

æ­¡è¿æäº¤ Pull Request æ–°å¢æˆ–ä¿®æ­£è¡“èªï¼
"""


def main():
    """Main function to build docs."""
    print("Loading categories...")
    categories = load_categories()
    print(f"  Loaded {len(categories)} categories")

    print("Loading terms...")
    terms = load_all_terms()
    print(f"  Loaded {len(terms)} terms")

    # Ensure directories exist
    GLOSSARY_DIR.mkdir(parents=True, exist_ok=True)
    CATEGORIES_DIR.mkdir(parents=True, exist_ok=True)
    API_DIR.mkdir(parents=True, exist_ok=True)
    API_TERMS_DIR.mkdir(parents=True, exist_ok=True)

    # Generate term pages
    print("Generating term pages...")
    for term in terms:
        term_id = term["id"]
        term_dir = GLOSSARY_DIR / term_id
        term_dir.mkdir(exist_ok=True)

        # Markdown
        md_content = generate_term_markdown(term, categories)
        (term_dir / "index.md").write_text(md_content, encoding="utf-8")

        # JSON API
        json_content = generate_term_json(term)
        (API_TERMS_DIR / f"{term_id}.json").write_text(
            json.dumps(json_content, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )

    print(f"  Generated {len(terms)} term pages")

    # Generate glossary index
    print("Generating glossary index...")
    glossary_index = generate_glossary_index(terms, categories)
    (GLOSSARY_DIR / "index.md").write_text(glossary_index, encoding="utf-8")

    # Generate categories index
    print("Generating categories index...")
    categories_index = generate_categories_index(terms, categories)
    (CATEGORIES_DIR / "index.md").write_text(categories_index, encoding="utf-8")

    # Generate API files
    print("Generating API files...")

    # All terms
    all_terms_json = [generate_term_json(t) for t in terms]
    (API_DIR / "terms.json").write_text(
        json.dumps({"terms": all_terms_json, "count": len(all_terms_json)},
                   ensure_ascii=False, indent=2),
        encoding="utf-8"
    )

    # Categories
    categories_json = list(categories.values())
    (API_DIR / "categories.json").write_text(
        json.dumps({"categories": categories_json, "count": len(categories_json)},
                   ensure_ascii=False, indent=2),
        encoding="utf-8"
    )

    # Generate API documentation
    print("Generating API documentation...")
    api_doc = generate_api_index()
    (DOCS_DIR / "api.md").write_text(api_doc, encoding="utf-8")

    # Generate home page
    print("Generating home page...")
    home_page = generate_home_page(terms, categories)
    (DOCS_DIR / "index.md").write_text(home_page, encoding="utf-8")

    print("Done!")
    print(f"  - {len(terms)} term pages in docs/glossary/")
    print(f"  - {len(terms)} JSON files in docs/api/v1/terms/")
    print(f"  - API index at docs/api/v1/terms.json")
    print(f"  - Categories at docs/api/v1/categories.json")


if __name__ == "__main__":
    main()
